---
title: "Trabalho"
subtitle: "Dados de Queimadas"
lang: pt-BR
author: "Mikael Marin Coletto"
date: "2024-10-01"
format:
  html:
    toc: true
    code-fold: true
    theme: cerulean
    transition: slide
    background-transition: fade
    embed-resources: true
    # anchor-sections: true 
    smooth-scroll: true
    center: true
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
options(scipen = 99999)
data_from <- "local"
descritiva <- F
# data_from <- "pendrive"
if(data_from == "local"){
  data_path <- "/mnt/Netac-Dados/Projetos/R/Pos-Estat/3-Semestre/Series-temporais/Trabalho/dados/"
}
if(data_from == "pendrive"){
  data_path <- "/media/userlm/Ventoy/Projetos/R/Pos-Estat/3-semestre/Series-temporais/Trabalho/dados/"
}
rewrite_data <- F
```

# Introdução

Neste trabalho, vamos analisar os dados de queimadas no Brasil. Os dados foram obtidos do portal BDQueimadas do INPE (Instituto Nacional de Pesquisas Espaciais) e estão disponíveis em [https://terrabrasilis.dpi.inpe.br/queimadas/bdqueimadas/#exportar-dados](https://terrabrasilis.dpi.inpe.br/queimadas/bdqueimadas/#exportar-dados).       

O intuito é analisar a quantidade de focos de queimadas por mês e ano, tentando identificar se houve um aumento no número de queimadas ao longo dos últimos anos.

# Carregando os dados

```{r, dados}
if(descritiva){
  dados_2023_2024 <- data.table::fread(paste0(data_path, "focos_qmd_inpe_2023-10-01_2024-10-01_32.767240.csv"))
  
  df_queimadas_2023_2024 <- dados_2023_2024 |> 
    dplyr::arrange(Estado, Municipio, DataHora)
  
  ## Verificando quantas informações temos cada município
  df_queimadas_2023_2024_ag_mun_sat <- df_queimadas_2023_2024 |> 
    dplyr::group_by(Municipio, Satelite) |> 
    dplyr::mutate(n = n()) |> 
    dplyr::distinct(Municipio, Satelite, .keep_all = T) |>
    dplyr::select(Estado, Municipio, Satelite, n) |> 
    dplyr::ungroup()
  
  df_top_22 <- df_queimadas_2023_2024_ag_mun_sat |> 
    # head(22)
    dplyr::slice(1:22)
  
  dados_2014_2015 <- data.table::fread(paste0(data_path, "focos_qmd_inpe_2014-10-01_2015-10-01_41.322529.csv"))
  
  df_queimadas_2014_2015 <- dados_2014_2015 |> 
    dplyr::arrange(Estado, Municipio, DataHora)
  
  ## Verificando quantas informações temos cada município
  df_queimadas_2014_2015_ag_mun_sat <- df_queimadas_2014_2015 |> 
    dplyr::group_by(Municipio, Satelite) |> 
    dplyr::mutate(n = n()) |> 
    dplyr::distinct(Municipio, Satelite, .keep_all = T) |>
    dplyr::select(Estado, Municipio, Satelite, n)
  
  ## Observando um município
  df_mun <- df_queimadas_2014_2015_ag_mun_sat |> 
    dplyr::filter(Municipio == "SÃO FÉLIX DO XINGU",
                  Satelite == "NPP-375")

}
```

## Análise inicial

### Verificando a quantidade de focos de queimadas por mês e ano de 2014/10 à 2015/9
```{r, analise-inicial}
if(descritiva){
  ## Verificando a quantidade de focos de queimadas por mês e ano
  format(lubridate::ymd_hms(df_queimadas_2014_2015[1,1]), "%Y-%m")
  
  df_queimadas_2014_2015_sample <- df_queimadas_2014_2015 |> 
    dplyr::sample_n(1000) |> 
    dplyr::mutate(DataHora_ = lubridate::ymd_hms(DataHora)) |>
    dplyr::mutate(Ano_mes = format(DataHora_, "%Y-%m")) |>
    dplyr::group_by(Ano_mes) |> 
    dplyr::summarise(n = n()) |> 
    dplyr::ungroup() |> 
    dplyr::mutate(Ano_mes = as.factor(Ano_mes))
  
  queimadas_ano_mes <- df_queimadas_2014_2015|> 
    dplyr::sample_n(1000) |> 
    dplyr::mutate(DataHora_ = lubridate::ymd_hms(DataHora)) |>
    dplyr::mutate(Ano_mes = format(DataHora_, "%Y-%m")) |>
    dplyr::filter(Ano_mes != "2015-10") |> 
    dplyr::group_by(Ano_mes) |> 
    dplyr::summarise(n = n()) |> 
    dplyr::ungroup()
  
  queimadas_ano_mes |> 
    ggplot(aes(x = Ano_mes, y = n)) +
    geom_col(position = "dodge", fill = "#407D97") +
    labs(title = "Focos de queimadas por mês e ano",
         x = "Ano/Mês",
         y = "Quantidade de focos") +
    theme_minimal()
}
```
### Verificando estado com mais focos de incêncio em 2014/10 à 2015/9

```{r, estado-mais-focos-2014-2014}
if(descritiva){
  df_estado <- df_queimadas_2014_2015 |> 
    dplyr::group_by(Estado) |> 
    dplyr::summarise(n = n()) |> 
    dplyr::arrange(desc(n))
  
  df_estado |>
    ggplot(aes(x = n, y = reorder(Estado, n))) +
    geom_col(fill = "#407D97") +
    labs(title = "Focos de queimadas por estado",
         x = "Estado",
         y = "Quantidade de focos") +
    theme_minimal()
}
```

### Verificando estado com mais focos de incêncio em 2023/10 à 2024/9

```{r, estado-mais-focos-2023-2024}
if(descritiva){
  df_estado_2023_2024 <- df_queimadas_2023_2024 |> 
    dplyr::group_by(Estado) |> 
    dplyr::summarise(n = n()) |> 
    dplyr::arrange(desc(n))
  
  df_estado_2023_2024 |>
    ggplot(aes(x = n, y = reorder(Estado, n))) +
    geom_col(fill = "#407D97") +
    labs(title = "Focos de queimadas por estado",
         x = "Estado",
         y = "Quantidade de focos") +
    theme_minimal()
}
```

## Preparando dados

Para esta avaliação, usaremos os dados apenas de um estado, pelos dados analisados anteriormente, os estados com maior número de focos de incêndio são o Pará e Mato Grosso, pelos dados coletados.
Portanto, faremos uma primeira análise com dados apenas do Pará.

```{r, preparando-dados}
if(rewrite_data){
  # Usando dados apenas de um município
  ## Município selecionado
  estado_sel <- "MATO GROSSO"
  satelite_sel <- "NPP- 375"
  ## Lendo todos os arquivos da pasta dados
  files <- list.files(paste0(data_path), full.names = T)
  ## Lendo os arquivos e selecionando apenas dados do estado e Satelite selecionados
  df_queimadas_estado <- lapply(files, function(x){
    dados <- data.table::fread(x)
    dados |> 
      dplyr::filter(Estado == estado_sel,
                    Satelite == satelite_sel)
  })
  ## Unindo todos os dados
  df_queimadas_estado <- dplyr::bind_rows(df_queimadas_estado)
  ## Removendo linhas duplicadas
  df_queimadas_estado <- df_queimadas_estado |> 
    dplyr::distinct()
  
## Verificando a quantidade de focos de queimadas por mês e ano
df_queimadas_estado_anomes <- df_queimadas_estado |> 
  dplyr::mutate(DataHora_ = lubridate::ymd_hms(DataHora)) |>
  dplyr::mutate(Ano_mes = format(DataHora_, "%Y-%m")) |>
  dplyr::group_by(Ano_mes) |> 
  dplyr::summarise(n = n()) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(Ano_mes = Ano_mes)
  
  ## Salvando os dados
  saveRDS(df_queimadas_estado_anomes, paste0(data_path, "df_queimadas_ma_anomes.rds"))
}else{
  df_queimadas_estado_anomes <- readRDS(paste0(data_path, "df_queimadas_ma_anomes.rds"))
  estado_sel <- "MATO GROSSO"
  satelite_sel <- "NPP-375"
}
```

# Série temporal

## Visualizando a série

```{r, visualizacoes}
## Fazendo gráfico de linhas da série temporal
df_queimadas_estado_anomes <- df_queimadas_estado_anomes |>
  mutate(Ano_mes = paste0(Ano_mes, "-01")) |> 
  mutate(Ano_mes = lubridate::ymd(Ano_mes))

df_queimadas_estado_anomes |> 
  ggplot(aes(x = Ano_mes, y = n, group = 1)) +
  geom_line() +
  labs(title = paste0 ("Focos de queimadas por mês e ano ", "no ", estado_sel),
       x = "Ano/Mês",
       y = "Quantidade de focos") +
  theme_minimal() +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year")

```
A primeira observação da série nos mostra que parece existir uma sazonalidade nos dados.

```{r, visualizacoes}
## Fazendo gráfico de linhas da série temporal apenas de um ano
df_queimadas_estado_anomes |>
  dplyr::filter(Ano_mes >= "2023-01-01" & Ano_mes <= "2023-12-01") |>
  dplyr::mutate(Ano_mes = as.Date(Ano_mes)) |> 
  ggplot(aes(x = Ano_mes, y = n, group = 1)) +
  geom_line() +
  labs(title = paste0 ("Focos de queimadas por mês em 2023 ", "no ", estado_sel),
       x = "",
       y = "Quantidade de focos no mês") +
  theme_minimal() +
  scale_x_date(date_labels = "%b", date_breaks = "1 month")

```
Olhando apenas em um ano, neste caso em 2023, podemos observar que o número de focos de queimadas aumenta no segundo semestre do ano. Sabemos que a época de secas no estado é de maio a setembro, o que pode explicar o aumento no número de focos de queimadas, já entre outubro e março temos o período de chuvas, onde vemos a queda do número de focos de incêndio até quase zero.


## Correlogramas

Agora vamos observar os correlogramas da nossa série temporal, usando o lag máximo de 36 para observar o período de alguns anos.

```{r, autocorrelacao}
## Autocorrelação dos dados de focos de queimadas no estado selecionado
forecast::Acf(df_queimadas_estado_anomes$n, type = "correlation", main = "Autocorrelação para volume de queimadas no mês", lag.max = 36)

## Autocorrelação parcial dos dados de focos de queimadas no estado selecionado
forecast::Acf(df_queimadas_estado_anomes$n, type = "partial", main = "Autocorrelação parcial para volume de queimadas no mês", lag.max = 36)
```

A análise do gráfico de autocorrelação nos dá indícios de algumas características da nossa série temporal.
No gráfico de autocorrelação não observamos uma queda até o valor 0 do lag 12, pelo contrário, vemos picos no lag 11 e 12, é um indício de que a série possui sazonalidade.
Já no gráfico deautocorrelação parcial, observamos quedas porém ainda existem outros picos fora do intervalo de confiança.

## Teste de raiz unitária

```{r, teste-raiz-unitaria}

## Transformando os dados em série temporal
ts_data <- ts(df_queimadas_estado_anomes$n, start = c(lubridate::year(min(df_queimadas_estado_anomes$Ano_mes)), lubridate::month(min(df_queimadas_estado_anomes$Ano_mes))), frequency = 12)


## Teste de Dickey-Fuller aumentado
aug_dic_ful_test <- tseries::adf.test(ts_data, alternative = "stationary")
print(aug_dic_ful_test)
## Teste Kwiatkowski-Phillips-Schmidt-Shin
kpss_test <- tseries::kpss.test(ts_data)
print(kpss_test)
# ## Teste phillips-perron
# phillips_perron_test <- tseries::pp.test(ts_data)
# print(phillips_perron_test)
```

O teste de Dickey-Fuller aumentado (ADF) é um teste de raiz unitária para uma amostra de uma série temporal. A hipótese nula do teste é que a série temporal possui uma raiz unitária, o que indica que a série não é estacionária. A hipótese alternativa (rejeitando a hipótese nula) é que a série temporal é estacionária. Rodando o teste nos dados da temperatura do molde T1, temos um resultado de p-valor `r round(aug_dic_ful_test$p.value, 3)`, ou seja, **rejeitamos a hipótese nula e aceitamos a hipótese alternativa** de que **a série temporal é estacionária**.

Já o teste de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) é outro teste que verifica raizes unitárias em tendência, e tem sua hipótese nula que a série é não estacionária, e a hipótese alternativa que a série é estacionária. Rodando o teste nos dados da temperatura do molde T1, temos um resultado de p-valor `r round(kpss_test$p.value, 3)`, ou seja, **reijeitamos a hipótese nula e aceitamos a hipótese alternativa** de que **a série temporal não é estacionária**.

Como temos uma discordância entre os testes, isso pode nos indicar uma raíz unitária fracionária, ou que a nossa série precisa de diferença para ser estabilizada. Vamos tentar dar uma diferença primeiro e verificar o comportamento da série.

## Diferenciação

```{r, diferenciacao}
decompose(ts_data) |> autoplot()

analisando_sazonalidade <- function(ts_data){
  # 1. Decomposition using both additive and multiplicative models
  if(any(ts_data <= 0)) {
    decomp <- decompose(ts_data, type="additive")
  } else {
    decomp <- decompose(ts_data, type="multiplicative")
  }
  
  # 2. Calculate seasonal strength
  seasonal_strength <- max(0, 1 - var(decomp$random, na.rm=TRUE) / 
                            var(decomp$seasonal + decomp$random, na.rm=TRUE))
  
  # 3. Perform Kruskal-Wallis test for seasonality
  # First, create factors for seasons/periods
  period <- frequency(ts_data)
  seasonal_factors <- factor(cycle(ts_data))
  kw_test <- kruskal.test(as.numeric(ts_data) ~ seasonal_factors)
  
  # 4. Calculate Friedman test for seasonality
  # Reshape data into a matrix with seasons in columns
  n_periods <- length(ts_data) %/% period
  ts_matrix <- matrix(head(as.numeric(ts_data), n_periods * period), 
                     ncol=period, byrow=TRUE)
  friedman_test <- friedman.test(ts_matrix)
  
  # 5. Create results list
  results <- list(
    decomposition = decomp,
    seasonal_strength = seasonal_strength,
    kruskal_wallis_test = kw_test,
    friedman_test = friedman_test
  )
  
  # 6. Print summary
  cat("\nAnálise de sazonalidade:\n")
  cat("--------------------------------\n")
  cat("Força da Sazonalidade:", seasonal_strength, "\n")
  cat("(Valores próximos de 1 indicam sazonalidade)\n\n")
  
  cat("Kruskal-Wallis Test:\n")
  cat("H0: Não há efeitos de sazonalidade\n")
  cat("p-value:", kw_test$p.value, "\n\n")
  
  cat("Friedman Test:\n")
  cat("H0: Não há efeitos de sazonalidade\n")
  cat("p-value:", friedman_test$p.value, "\n")
  cat("--------------------------------\n")
}

analisando_sazonalidade(ts_data)
```

Pelos testes rodados, todos indicam que existe sazonalidade e que há uma forte sazonalidade, portanto partiremos para modelos SARIMA diretamente.

## Modelo SARIMA

```{r, modelo-arima}
## Dividindo os dados em treino e teste
df_queimadas_estado_anomes <- df_queimadas_estado_anomes |> 
  dplyr::mutate(Ano_mes = as.Date(paste0(Ano_mes, "-01")))

df_queimadas_estado_anomes_treino <- df_queimadas_estado_anomes |>
  dplyr::filter(Ano_mes < "2024-01-01" & Ano_mes > "2015-01-01")

df_queimadas_estado_anomes_teste <- df_queimadas_estado_anomes |>
  dplyr::filter(Ano_mes >= "2024-01-01")

## Transformando os dados em série temporal
ts_data_model <- ts(df_queimadas_estado_anomes_treino$n, start = c(lubridate::year(min(df_queimadas_estado_anomes_treino$Ano_mes)), lubridate::month(min(df_queimadas_estado_anomes_treino$Ano_mes))), frequency = 12)

# auto.arima(ts_data, seasonal = TRUE)
# ts_data_model <- na.omit(ts_data_model)
fit_arima <- forecast::Arima(ts_data_model, order = c(1, 0, 0))
fit_arima$aic
## Coeficientes do modelo
coeficientes_arima <- lmtest::coeftest(fit_arima)

# Function to analyze and fit SARIMA model
analyze_and_fit_sarima <- function(ts_data_model, forecast_periods = 12) {
  library(forecast)
  library(stats)
  
  # 1. Analyze the series
  # Check if differencing is needed
  ndiffs_result <- ndiffs(ts_data_model)  # for non-seasonal differencing
  nsdiffs_result <- nsdiffs(ts_data_model, m = 12)  # for seasonal differencing
  
  # 2. Auto ARIMA to get initial parameters
  # This helps us get a baseline model
  auto_fit <- auto.arima(ts_data_model, 
                        seasonal = TRUE,
                        stepwise = TRUE,
                        approximation = FALSE,
                        trace = TRUE)  # shows model selection process
  
  # Print model information
  cat("\nModel Analysis Results:\n")
  cat("--------------------------------\n")
  cat("Recommended differences (non-seasonal):", ndiffs_result, "\n")
  cat("Recommended differences (seasonal):", nsdiffs_result, "\n")
  cat("\nAuto ARIMA suggested parameters:\n")
  cat("ARIMA", auto_fit$arma, "\n")
  cat("with seasonal period", auto_fit$seasonal$period, "\n\n")
  
  # 3. Manual SARIMA specification
  # Example: SARIMA(1,1,1)(1,1,1)[12]
  # Modify these parameters based on your analysis
  sarima_model <- Arima(ts_data_model,
                       order = c(1,1,1),  # non-seasonal part (p,d,q)
                       seasonal = list(order = c(1,1,1),  # seasonal part (P,D,Q)
                                    period = 12))         # monthly data
  
  # 4. Model diagnostics
  checkresiduals(sarima_model)
  
  # 5. Generate forecasts
  forecasts <- forecast(sarima_model, h = forecast_periods)
  
  # 6. Return results
  return(list(
    auto_model = auto_fit,
    manual_model = sarima_model,
    forecasts = forecasts,
    residuals_test = Box.test(sarima_model$residuals, type = "Ljung-Box")
  ))
}

# Example usage:
results <- analyze_and_fit_sarima(ts_data_model)

```

O modelo SARIMA 

```{r, analisando resíduos}
#| warning: false

sarima_model <- Arima(ts_data_model,
                       order = c(1,1,1),  # non-seasonal part (p,d,q)
                       seasonal = list(order = c(1,1,1),  # seasonal part (P,D,Q)
                                    period = 12))         # monthly data

## Analisando modelo
fitted_values <- fitted(sarima_model)

dates <- df_queimadas_estado_anomes_treino$Ano_mes
# 1:length(ts_data_model)

ggplot() +
  geom_line(aes(x = dates, y = ts_data_model, color = "Dados originais"), lwd = 1) +
  geom_line(aes(x = dates, y = fitted_values, color = "SARIMA(1,0,0)(2,1,0)[12]"), lwd = 0.5) +
  labs(title = "Dados originais e modelo ajustado",
       subtitle = "Número de focos de incêndio",
       x = "",
       y = "",
       color = "Legend") +
  scale_color_manual(values = c("Dados originais" = "black", "SARIMA(1,0,0)(2,1,0)[12]" = "red")) +
  theme_minimal()

```
### Analisando resíduos

```{r, analisando-residuos}
residuals <- residuals(sarima_model)

# 
ggplot() +
  geom_line(aes(x = time(residuals), y = residuals)) +
  labs(title = "Resíduos no tempo", x = "Time", y = "Resíduos") +
  theme_minimal()

par(mfrow = c(1, 2))

forecast::Acf(residuals, type = "correlation", main = "AC of Residuals")
forecast::Acf(residuals, type = "partial", main = "ACF of Residuals")

### Resíduos padronizados
# residuals_standardized <- residuals / sd(residuals)
# ggplot() +
#   geom_line(aes(x = time(residuals_standardized), y = residuals_standardized)) +
#   labs(title = "Standardized Residuals vs. Time", x = "Time", y = "Standardized Residuals") +
#   theme_minimal()

dados_residuos_queimadas <- as.data.frame(residuals)


# Normalização Min-Max
dados_normalizados <- dados_residuos_queimadas %>%
  mutate(contagem_normalizada = (x - min(x)) / (max(x) - min(x)))

dados <- dados_residuos_queimadas |> 
  mutate(contagem_log = log(x + 1))  # Adiciona 1 para evitar log(0)

# Verificar a normalidade após a transformação
shapiro.test(dados$contagem_log)

dados <- dados_residuos_queimadas %>%
  mutate(contagem_sqrt = sqrt(x))

# Verificar a normalidade após a transformação
shapiro.test(dados$contagem_sqrt)

# Aplicar Box-Cox (supondo que 'contagem' > 0)
boxcox_result <- boxcox(lm(x ~ 1, data = dados_residuos_queimadas), lambda = seq(-2, 2, by = 0.1))

# Melhor valor de lambda
best_lambda <- boxcox_result$x[which.max(boxcox_result$y)]

# Transformação dos dados com o melhor lambda
dados <- dados_2010_2020_hans_anomes |> 
  mutate(contagem_boxcox = ifelse(
    abs(best_lambda) < 1e-10,  # Verifica se lambda está próximo de zero
    log(n),                    # Usa logaritmo se lambda ≈ 0
    (n^best_lambda - 1) / best_lambda
  ))

# Verificar a normalidade após a transformação
shapiro.test(dados$contagem_boxcox)


```

```{r}
## Testando normalidade nos resíduos
shapiro.test(residuals)

```

## Modelo ARFIMA

```{r, modelo-arfima}
library(arfima)
# Modelo ARFIMA
fit_arfima <- fracdiff::fracdiff(ts_data_model)
d <- fit_arfima$d
fit_arfima <- arima(ts_data_model, order = c(1, d, 0))


## Coeficientes do modelo
lmtest::coeftest(fit_arfima)

# fit_arfima <- arfima::arfima(ts_data_model, order = c(1, 0, 0), seasonal = list(order = c(2, 0, 1), period = 12))
# fit_arfima_2 <- arfima::arfima(ts_data_model, order = c(1, 0, 0), seasonal = list(order = c(2, 0, 1), period = 12))
# fit_arfima_forecast <- forecast::arfima(ts_data_model, order = c(1, 0, 0), seasonal = list(order = c(2, 0, 1), period = 12))

# forecast::arfima(ts_data_model, order = c(1, 0, 0), seasonal = list(order = c(2, 0, 1), period = 12))
# arfima::bestModes(fit_arfima, 5)

## Coeficientes do modelo
fit_arfima

## Analisando modelo
fitted_values_arfima <- fitted(fit_arfima)

# ggplot() +
#   geom_line(aes(x = dates, y = ts_data_model, color = "Dados originais"), lwd = 1) +
#   geom_line(aes(x = dates, y = fitted_values_arfima, color = "ARFIMA(1,1)"), lwd = 1) +
#   labs(title = "Dados originais e modelo ajustado",
#        subtitle = "Número de focos de incêndio",
#        x = "",
#        y = "",
#        color = "Legend") +
#   scale_color_manual(values = c("Dados originais" = "black", "ARFIMA(1,1)" = "red")) +
#   theme_minimal()

```

## Modelo ARMAX

```{r, modelo-armax}
## Modelo ARMAX
# # fit_armax <- forecast::Arima(ts_data_model, order = c(1, 0, 1), seasonal = c(12, 0, 1), xreg = )
# 
# ## Coeficientes do modelo
# lmtest::coeftest(fit_armax)
# 
# ## Analisando modelo
# fitted_values_armax <- fitted(fit_armax)
# 
# ggplot() +
#   geom_line(aes(x = dates, y = ts_data_model, color = "Dados originais"), lwd = 1) +
#   geom_line(aes(x = dates, y = fitted_values_armax, color = "ARMAX(1,0,1)(12,0,1)"), lwd = 1) +
#   labs(title = "Dados originais e modelo ajustado",
#        subtitle = "Número de focos de incêndio",
#        x = "",
#        y = "",
#        color = "Legend") +
#   scale_color_manual(values = c("Dados originais" = "black", "ARMAX(1,0,1)(12,0,1)" = "red")) +
  # theme_minimal()
```

